# Testing and Evaluations of Language Models and Transformers

This repository contains code and resources for testing and evaluating various language models and transformers. Our goal is to provide a comprehensive benchmarking platform for these models, and to contribute to the understanding and improvement of these powerful tools. We aim to test and evaluate various language models and transformers. Our testing framework includes both qualitative and quantitative evaluations.


## Tasks

We test the models on a variety of tasks to evaluate their performance and robustness. These tasks include but are not limited to:

- Classification Tasks
    - Text Classification : Categorizing text into predefined classes or categories.
    - Sentiment Analysis : Determining the sentiment or emotion expressed in a piece of text. 
    - Reading Comprehension : Understanding and answering questions based on a given text.
    - Analyze and Evaluate : Assessing and evaluating text based on specific criteria.
    - Topic Modeling : Identifying topics or themes within a collection of documents.
    - Intent Recognition : Determining the user's intention or goal behind a given text.
- Generation Tasks
    - Text Generation : Creating new text based on certain conditions or prompts.
    - Ideas and Brainstorming : Generating creative writing prompts, ideas, and brainstorming sessions. 
    - Copywriting and Marketing : Creating persuasive and engaging content for marketing and advertising purposes.
    - Question Generation : Crafting relevant and meaningful questions based on a given text.
- Transformation Tasks
    - Paraphrasing : Rewriting text to convey the same meaning using different words.
    - Translation : Converting text from one language to another.
    - Proofreading and Editing : Correcting and improving text for grammar, style, and clarity. 
    - Stylometry : Modifying text to match a specific writing style or author's voice.
    - Simplification : Rewriting complex text to make it more understandable for a wider audience.
    - Language Style Transfer : Adapting the style of a text to match a specific tone, formality level, or dialect.
- Comparison Tasks
    - Comparison : Comparing two or more pieces of text based on specific attributes.
    - Compare and Contrast : Identifying similarities and differences between two or more texts.
    - Near-Duplicate Detection: Identifying nearly identical instances of text, useful for detecting content redundancy or repurposing.
    - Textual Similarity: Measuring the degree of semantic similarity or equivalence between two pieces of text.
- Extraction Tasks
    - Information Extraction : Extracting specific information or data from unstructured text.
    - Named Entity Recognition : Identifying and classifying named entities (e.g., person names, locations, organizations) in text.
    - Keyword Extraction : Identifying and extracting significant words or phrases from a given text. 
    - Relation Extraction : Discovering and categorizing relationships between entities within a text.
- Summarization Tasks
    - Text Summarization : Creating a concise summary of a longer piece of text.
    - Extractive Summarization : Generating a summary by selecting important sentences or phrases from the original text.
    - Abstractive Summarization : Producing a summary that captures the main points of the original text, but may use new wording or phrasing.
- Synthesis Tasks
    - Synthesis and Merging : Combining information from multiple sources to create a coherent and comprehensive output. 
- Programming Tasks
    - Natural Language Programming : Using natural language to interact with or instruct computer programs.
    - Code Generation : Automatically generating code based on natural language descriptions or specifications.
    - Natural Language Interface : Allowing users to interact with software applications through natural language commands or queries.
    - Automated Debugging : Identifying and fixing programming errors based on natural language descriptions of the problem.
- Inference Tasks
    - Implicit Information Extraction: Inferring information that is not explicitly stated in the text.
    - Commonsense Reasoning: Making inferences about everyday situations and events.
    - Natural Language Inference: Determining whether a statement is true, false, or indeterminable based on a given context.
    - Textual Entailment: Determining whether a given text implies a hypothesis or statement.

## Evaluation Metrics

We use a variety of metrics to evaluate the models, including:

- Accuracy
- Truthfulness
- Perplexity
- BLEU score

In addition to these, also evaluations for:

- Language: Assessing linguistic capabilities.
- Knowledge: Evaluating knowledge (e.g. factual, cultural, commonsense).
- Reasoning: Evaluating reasoning capabilities (e.g. mathematical, hierarchical).
- Harms: Evaluating potential social harms (e.g., copyright, disinformation, social bias, toxicity).
- Efficiency: Evaluating training and inference efficiency.

## Results

We present our results in the form of tables and graphs and will be available in [Results](./Results) directory.
